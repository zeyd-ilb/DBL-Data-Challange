First get the cleaned data from the link below. Import the data to mongodb with "import_jsons_w_prepocess.py". After import is done run "duplicate_detele.py". 
Cleaned Data link: https://drive.google.com/file/d/1-6xE6I_2iiRiGZ-A9UX846D8KEDvT-1J/view

If you want to clean the data by yourself:
  1) run "cleaning.py" on the raw data
  2) import the cleaned data to mongodb with "import_jsons_w_prepocess.py"
  3) Configure the file names in "find_rt's_with_no_original.py" then run 
  4) You need to get ids of retweets that doesn't have originals which is also present in "uncommon.txt"  
  5) Then run "cleaning.py" with giving "uncommon.txt" into it
  6) After the cleaning is done repeat step 2 with the new cleaned data
  7) After import is done run "duplicate_delete.py" on mongodb for the new cleaned data.
